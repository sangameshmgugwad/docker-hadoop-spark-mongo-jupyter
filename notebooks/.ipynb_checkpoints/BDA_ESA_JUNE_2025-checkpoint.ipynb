{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09ba43f-28a1-4f48-83b0-5bc030e94673",
   "metadata": {},
   "source": [
    "Using PySpark and Spark-SQL libraries process the given dataset in order to find out solutions\n",
    "of queries mentioned below.\n",
    "\n",
    "1. Whatâ€™s the overall minimum, maximum, and average profit from the dataset?\n",
    "2. Which state has the most startups?\n",
    "3. What is the average administration cost for startups in Florida?\n",
    "4. How many startups are located in California?\n",
    "5. Out of all startups with a profit over 100,000, how many spent less than 50,000 on marketing?\n",
    "6. Remove the feature 'sl_no' and also remove rows with any null values from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06c7547-b42a-49e8-aa63-0c9ebb2dafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, min, max, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ccfaff-c0d4-44b6-95c3-90c3e7532845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------------+---------------+----------+---------+\n",
      "|sl_no|R&D Spend|Administration|Marketing Spend|     State|   Profit|\n",
      "+-----+---------+--------------+---------------+----------+---------+\n",
      "|    1| 165349.2|      136897.8|       471784.1|  New York|192261.83|\n",
      "|    2| 162597.7|     151377.59|      443898.53|California|191792.06|\n",
      "|    3|153441.51|     101145.55|      407934.54|   Florida|191050.39|\n",
      "|    4|144372.41|     118671.85|      383199.62|  New York|182901.99|\n",
      "|    5|142107.34|      91391.77|      366168.42|   Florida|166187.94|\n",
      "+-----+---------+--------------+---------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Stop any zombie sessions first\n",
    "if 'spark' in locals():\n",
    "    spark.stop()\n",
    "\n",
    "# 2. Re-initialize a fresh session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StartupAnalysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv(\"june_2025_startups_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Register as a Temp View for Spark-SQL\n",
    "df.createOrReplaceTempView(\"startups\")\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7afbc-9731-416f-b50f-580202d243d2",
   "metadata": {},
   "source": [
    "#### 1. Whatâ€™s the overall minimum, maximum, and average profit from the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a74a3de-3446-43c9-adb5-46f3a43e4b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+\n",
      "|Min_Profit|Max_Profit|        Avg_Profit|\n",
      "+----------+----------+------------------+\n",
      "| 129917.04| 192261.83|159414.89533333335|\n",
      "+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    min(\"Profit\").alias(\"Min_Profit\"),\n",
    "    max(\"Profit\").alias(\"Max_Profit\"),\n",
    "    avg(\"Profit\").alias(\"Avg_Profit\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87774bf2-e48e-45c6-a0a7-8ddb4fe10d0d",
   "metadata": {},
   "source": [
    "#### 2.Which state has the most startups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542ab5fd-f846-4f1e-b6ca-85a3fc5c127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     State|count|\n",
      "+----------+-----+\n",
      "|California|    6|\n",
      "+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"State\").count().orderBy(col(\"count\").desc()).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc693b2e-6317-4de4-8153-1beee3e11f09",
   "metadata": {},
   "source": [
    "#### 3.What is the average administration cost for startups in Florida?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b9d74a5-b427-4daf-9ae6-c010695505bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|avg(Administration)|\n",
      "+-------------------+\n",
      "|         115196.374|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.State == \"Florida\").select(avg(\"Administration\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905ddff-4359-42d9-8151-8762bfd0b165",
   "metadata": {},
   "source": [
    "#### 4. How many startups are located in California?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd27b28-1eda-477e-b0f0-9e1b000cfccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startups in California: 6\n"
     ]
    }
   ],
   "source": [
    "ca_count = df.filter(df.State == \"California\").count()\n",
    "print(f\"Startups in California: {ca_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee3ef8-1446-432f-8f20-395608500356",
   "metadata": {},
   "source": [
    "#### 5.Out of all startups with a profit over 100,000, how many spent less than 50,000 on marketing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630653f9-08fa-49af-8de4-59be98e9a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficient Startups: 1\n"
     ]
    }
   ],
   "source": [
    "efficient_startups = df.filter((col(\"Profit\") > 100000) & (col(\"Marketing Spend\") < 50000))\n",
    "print(f\"Efficient Startups: {efficient_startups.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb022583-a5fd-4eb9-a0ed-6745ca032b06",
   "metadata": {},
   "source": [
    "#### 6. Remove the feature 'sl_no' and also remove rows with any null values from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24331e3-c1b2-47d9-a287-6e3cfcea1b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+----------+---------+\n",
      "|R&D Spend|Administration|Marketing Spend|     State|   Profit|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "| 165349.2|      136897.8|       471784.1|  New York|192261.83|\n",
      "| 162597.7|     151377.59|      443898.53|California|191792.06|\n",
      "|153441.51|     101145.55|      407934.54|   Florida|191050.39|\n",
      "|144372.41|     118671.85|      383199.62|  New York|182901.99|\n",
      "|142107.34|      91391.77|      366168.42|   Florida|166187.94|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.drop(\"sl_no\").dropna()\n",
    "df_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef06ba-9602-4ad2-bc69-36bd31380943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1de3de2-fcbc-4201-9aab-132706f92bbe",
   "metadata": {},
   "source": [
    "Using Spark ML libraries process the Dataframe as questioned below.\n",
    "1. Use StringIndexer to replace all string-type columns with numerical representations. Confirm the DataFrame no longer has any columns with string data types.\n",
    "2. Using VectorAssembler, combine all columns (except target column i.e., Profit) into a single column named features. Ensure the DataFrame now has only two columns: features and Profit.\n",
    "3. Split the vectorized DataFrame into training and test sets with one-fourth records held for testing.\n",
    "4. Build a LinearRegression model on the train set using featuresCol=\"features\" and labelCol=\"Profit\"\n",
    "5. Perform prediction on the test data and print the Mean Squared Error (MSE) value.\n",
    "6. Calculate the Root Mean Squared Error (RMSE) for the predictions made by the linear regression model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52ccbcd-289c-4eac-a3cd-cfb3e866a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4540b963-14d7-4a0c-be73-5b8d53a7b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Stop any zombie sessions first\n",
    "if 'spark' in locals():\n",
    "    spark.stop()\n",
    "\n",
    "# 2. Re-initialize a fresh session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StartupAnalysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv(\"june_2025_startups_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a322ef1a-654f-42fb-9b3f-94a76372e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-cleaning: Remove 'sl_no' and null values\n",
    "df_cleaned = df.drop(\"sl_no\").dropna()\n",
    "\n",
    "# 1. Use StringIndexer to replace string columns with numerical representations\n",
    "indexer = StringIndexer(inputCol=\"State\", outputCol=\"State_Index\")\n",
    "df_indexed = indexer.fit(df_cleaned).transform(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc9142e6-3ecc-4501-a669-5dead8fc1dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- R&D Spend: double (nullable = true)\n",
      " |-- Administration: double (nullable = true)\n",
      " |-- Marketing Spend: double (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- State_Index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirming no columns with string data types (we drop the original 'State' column)\n",
    "df_final = df_indexed.drop(\"State\")\n",
    "df_final.printSchema() \n",
    "# Confirm: Only numeric (double/int) and Vector types remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324a4258-2864-4854-b06c-45e259953c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|   Profit|\n",
      "+--------------------+---------+\n",
      "|[165349.2,136897....|192261.83|\n",
      "|[162597.7,151377....|191792.06|\n",
      "|[153441.51,101145...|191050.39|\n",
      "|[144372.41,118671...|182901.99|\n",
      "|[142107.34,91391....|166187.94|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. VectorAssembler to combine feature columns (except Profit)\n",
    "# Feature columns include: RD_Spend, Administration, Marketing_Spend, State_Index\n",
    "feature_cols = [col for col in df_final.columns if col != \"Profit\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Select only 'features' and 'Profit'\n",
    "df_vectorized = assembler.transform(df_final).select(\"features\", \"Profit\")\n",
    "df_vectorized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98d8a9a7-d9b6-4e0f-bdb2-b5d6b90c3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 170748867.93215483\n",
      "Root Mean Squared Error (RMSE): 13067.091027927938\n"
     ]
    }
   ],
   "source": [
    "# 3. Split data into training and test sets (25% held for testing)\n",
    "train_data, test_data = df_vectorized.randomSplit([0.75, 0.25], seed=42)\n",
    "\n",
    "# 4. Build a LinearRegression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Profit\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# 5. Perform predictions on test data and calculate MSE\n",
    "predictions = lr_model.transform(test_data)\n",
    "evaluator_mse = RegressionEvaluator(labelCol=\"Profit\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator_mse.evaluate(predictions)\n",
    "\n",
    "# 6. Calculate RMSE\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Profit\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d7f85-e14c-488a-bc15-a2db7e19dd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
